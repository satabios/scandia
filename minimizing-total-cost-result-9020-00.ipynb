{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "0a883ac9-5b27-4a12-9c53-fac5669647fe",
    "_uuid": "82041574cced9a4277e0f911db5b86fb5a335374"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostRegressor, BaggingClassifier, BaggingRegressor, ExtraTreesClassifier, ExtraTreesRegressor\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "import scipy.cluster.hierarchy as hac\n",
    "\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "9e551517-2a76-438a-9b43-a1a38f60044f",
    "_uuid": "51abeef3225cca1ba18c31199ec4980f2c130d1f"
   },
   "outputs": [],
   "source": [
    "# Set normalization\n",
    "enable_normalization = True\n",
    "normalization_type = 'minmax' # 'minmax' or 'standard'\n",
    "\n",
    "# Exploratory analysis\n",
    "\n",
    "# Set correlation\n",
    "enable_correlation = False\n",
    "enable_dendrogram = False\n",
    "enable_heatmap = False\n",
    "\n",
    "# Features Selection\n",
    "\n",
    "# Set features selection with correlation criteria\n",
    "enable_correlation_selec = False\n",
    "factor = 0.95 # number close to 1\n",
    "\n",
    "# Set features selection with univariate statitics test criteria\n",
    "enable_univariate_selec = True\n",
    "method_selec = 'selectkbest' # 'selectkbest', 'pca', ...\n",
    "pca_variance = 0.95 \n",
    "criteria_k_best = mutual_info_classif # chi2, mutual_info_classif\n",
    "k_best = 84 # number of best features to select on select k best.\n",
    "\n",
    "# Balancing\n",
    "\n",
    "# Train balancing\n",
    "enable_balancing = True\n",
    "number_samples = 2500\n",
    "\n",
    "# Machine learning method\n",
    "\n",
    "ml_method = 'randomforestreg' # 'gradientboosting', 'svm', ...\n",
    "gbc_loss = 'deviance' # gradient boosting loss\n",
    "rfc_criterion = 'gini' # random forest criterion\n",
    "enable_cv = True # enable cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "c886a7cc-f168-449e-8bb6-d78f6f9041fb",
    "_uuid": "ad165cded227806fe7578f2f851696040a5445c5"
   },
   "outputs": [],
   "source": [
    "# Print the bar graph from data\n",
    "def bar(acumm_data):\n",
    "    # Do plot\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax = sns.barplot(x=acumm_data.index, y=acumm_data.values, palette='tab20b', ax=ax)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)    \n",
    "    return ax\n",
    "\n",
    "def dendrogram(df):    \n",
    "    # Do correlation matrix\n",
    "    corr_matrix = df.corr()\n",
    "\n",
    "    # Do the clustering\n",
    "    Z = hac.linkage(corr_matrix, 'single')\n",
    "\n",
    "    # Plot dendogram\n",
    "    fig, ax = plt.subplots(figsize=(25, 10))\n",
    "    plt.title('Hierarchical Clustering Dendrogram')\n",
    "    plt.xlabel('sample index')\n",
    "    plt.ylabel('distance')\n",
    "    groups = hac.dendrogram(\n",
    "        Z,\n",
    "        leaf_rotation=90.,  # rotates the x axis labels\n",
    "        leaf_font_size=8., # font size for the x axis labels\n",
    "        color_threshold = 0#,\n",
    "        #truncate_mode='lastp',\n",
    "        #p=30\n",
    "    )\n",
    "\n",
    "    labels_dict = pd.DataFrame(df.columns).to_dict()[0]\n",
    "    actual_labels = [item.get_text() for item in ax.get_xticklabels()]\n",
    "    new_labels = [labels_dict[int(i)] for i in actual_labels]\n",
    "    ax.set_xticklabels(new_labels)\n",
    "    plt.tight_layout()\n",
    "\n",
    "def corr_drop(corr_m, factor=.9):\n",
    "    \n",
    "    global cm\n",
    "    cm = corr_m\n",
    "    # Get correlation score, as high as this score, more chances to be dropped.\n",
    "    cum_corr = cm.applymap(abs).sum()\n",
    "    def remove_corr():\n",
    "        global cm\n",
    "        for col in cm.columns:\n",
    "            for ind in cm.index:\n",
    "                if (ind in cm.columns) and (col in cm.index):\n",
    "                    # Compare if are high correlated.\n",
    "                    if (cm.loc[ind,col] > factor) and (ind!=col):\n",
    "                        cum = cum_corr[[ind,col]].sort_values(ascending=False)\n",
    "                        cm.drop(cum.index[0], axis=0, inplace=True)\n",
    "                        cm.drop(cum.index[0], axis=1, inplace=True)\n",
    "                        # Do recursion until the last high correlated.\n",
    "                        remove_corr()\n",
    "        return cm\n",
    "    return remove_corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "68730eee-06af-42da-8f04-c0617f972aea",
    "_uuid": "89c8b03dffaa7d1be9be6402145d9c8970faf237"
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('./aps_failure_training_set_processed_8bit.csv', na_values='na')\n",
    "test_features =  pd.read_csv('./aps_failure_test_set_processed_8bit.csv', na_values='na')\n",
    "\n",
    "train_labels = train_features['class']\n",
    "test_labels = test_features['class']\n",
    "train_features = train_features.drop('class', axis=1)\n",
    "test_features = test_features.drop('class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "931cb280-82d4-44f7-aea5-5e732ca7c89e",
    "_uuid": "b7e20f7aaa6ca7307669071e84015ba728b364ac"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.124611</td>\n",
       "      <td>-0.071121</td>\n",
       "      <td>-0.198529</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>-0.033483</td>\n",
       "      <td>-0.040633</td>\n",
       "      <td>-0.006584</td>\n",
       "      <td>-0.026241</td>\n",
       "      <td>-0.040699</td>\n",
       "      <td>-0.074768</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104808</td>\n",
       "      <td>-0.098734</td>\n",
       "      <td>-0.094976</td>\n",
       "      <td>-0.089227</td>\n",
       "      <td>-0.103374</td>\n",
       "      <td>-0.088961</td>\n",
       "      <td>-0.084540</td>\n",
       "      <td>-0.067471</td>\n",
       "      <td>-0.020035</td>\n",
       "      <td>-0.018417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.367680</td>\n",
       "      <td>0.356812</td>\n",
       "      <td>0.564872</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.107086</td>\n",
       "      <td>0.111752</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.105864</td>\n",
       "      <td>0.186822</td>\n",
       "      <td>...</td>\n",
       "      <td>0.356547</td>\n",
       "      <td>0.362066</td>\n",
       "      <td>0.363148</td>\n",
       "      <td>0.336121</td>\n",
       "      <td>0.320314</td>\n",
       "      <td>0.237613</td>\n",
       "      <td>0.363893</td>\n",
       "      <td>0.261009</td>\n",
       "      <td>0.051907</td>\n",
       "      <td>0.061751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.351562</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.398438</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.382812</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.343750</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.304688</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.289062</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.195312</td>\n",
       "      <td>-0.179688</td>\n",
       "      <td>-0.226562</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.296875</td>\n",
       "      <td>-0.171875</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.070312</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.468750</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.046875</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>-0.031250</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.117188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>-0.054688</td>\n",
       "      <td>-0.101562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.132812</td>\n",
       "      <td>-0.023438</td>\n",
       "      <td>-0.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.992188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aa_000        ab_000        ac_000        ad_000        ae_000  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean      -0.124611     -0.071121     -0.198529     -0.007737     -0.033483   \n",
       "std        0.367680      0.356812      0.564872      0.004138      0.107086   \n",
       "min       -0.406250     -0.289062     -0.468750     -0.007812     -0.046875   \n",
       "25%       -0.398438     -0.289062     -0.468750     -0.007812     -0.046875   \n",
       "50%       -0.195312     -0.289062     -0.468750     -0.007812     -0.046875   \n",
       "75%       -0.070312      0.000000     -0.468750     -0.007812     -0.046875   \n",
       "max        0.992188      0.992188      0.992188      0.992188      0.992188   \n",
       "\n",
       "             af_000        ag_000        ag_001        ag_002        ag_003  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean      -0.040633     -0.006584     -0.026241     -0.040699     -0.074768   \n",
       "std        0.111752      0.032016      0.065200      0.105864      0.186822   \n",
       "min       -0.054688     -0.007812     -0.031250     -0.054688     -0.117188   \n",
       "25%       -0.054688     -0.007812     -0.031250     -0.054688     -0.117188   \n",
       "50%       -0.054688     -0.007812     -0.031250     -0.054688     -0.117188   \n",
       "75%       -0.054688     -0.007812     -0.031250     -0.054688     -0.117188   \n",
       "max        0.992188      0.992188      0.992188      0.992188      0.992188   \n",
       "\n",
       "       ...        ee_002        ee_003        ee_004        ee_005  \\\n",
       "count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean   ...     -0.104808     -0.098734     -0.094976     -0.089227   \n",
       "std    ...      0.356547      0.362066      0.363148      0.336121   \n",
       "min    ...     -0.382812     -0.382812     -0.382812     -0.351562   \n",
       "25%    ...     -0.382812     -0.382812     -0.375000     -0.343750   \n",
       "50%    ...     -0.179688     -0.179688     -0.195312     -0.179688   \n",
       "75%    ...     -0.007812      0.015625      0.015625      0.007812   \n",
       "max    ...      0.992188      0.992188      0.992188      0.992188   \n",
       "\n",
       "             ee_006        ee_007        ee_008        ee_009        ef_000  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean      -0.103374     -0.088961     -0.084540     -0.067471     -0.020035   \n",
       "std        0.320314      0.237613      0.363893      0.261009      0.051907   \n",
       "min       -0.312500     -0.195312     -0.304688     -0.171875     -0.023438   \n",
       "25%       -0.312500     -0.195312     -0.304688     -0.171875     -0.023438   \n",
       "50%       -0.226562     -0.171875     -0.296875     -0.171875     -0.023438   \n",
       "75%       -0.054688     -0.101562      0.000000     -0.132812     -0.023438   \n",
       "max        0.992188      0.992188      0.992188      0.992188      0.992188   \n",
       "\n",
       "             eg_000  \n",
       "count  60000.000000  \n",
       "mean      -0.018417  \n",
       "std        0.061751  \n",
       "min       -0.023438  \n",
       "25%       -0.023438  \n",
       "50%       -0.023438  \n",
       "75%       -0.023438  \n",
       "max        0.992188  \n",
       "\n",
       "[8 rows x 170 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c140038b-9c89-4a30-ae3b-b034eb7efce0",
    "_uuid": "ce84dcfaa2d6d93d69ff283148b91b9d18f6a9cf"
   },
   "source": [
    "### Flat dataframe and check for non-valid values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "02391966-684f-4457-bd52-4a0fb59e52bd",
    "_uuid": "918309c9769b84d42be3698f5b2c3f07627328b1"
   },
   "source": [
    "If doesn't exist, it is considered non-valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "a66c9941-449d-418c-bcd9-2dff01809875",
    "_uuid": "5bf6e59bfc785d5600631a9cb7f0680056a85852"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% of data are non-valid.\n"
     ]
    }
   ],
   "source": [
    "flat_data = train_features.values.flatten()\n",
    "count=0\n",
    "for value in flat_data:\n",
    "    if value is not None:\n",
    "        continue\n",
    "    count+= 1\n",
    "pct_nan = round(100*count/len(flat_data))\n",
    "print(f'{pct_nan}% of data are non-valid.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "111b2686-3065-4a9e-8a92-4e464c9d1071",
    "_uuid": "16e5b816495d0319cd03c9ee95c36b6cd26958d8"
   },
   "source": [
    "### Scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "96959148-dd44-4524-9315-b3778ea8471f",
    "_uuid": "ab80e7c210fa085cc93c05546ab7e3a3a1282fc4"
   },
   "source": [
    "Apply MinMaxScaler with values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4fd91abf-8a1c-413e-b2da-215e398537ba",
    "_uuid": "b0d0dc410e1db2327172551647e2d69b10b4abb4"
   },
   "source": [
    "Ref: http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "1e2c4de2-3842-43ef-9737-ba5f9f83b55d",
    "_uuid": "d75ad2e36a03cd2ae222ad4de9413c35043b5652"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "if enable_normalization and normalization_type=='minmax':\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(train_features)\n",
    "    train_features = pd.DataFrame(scaler.transform(train_features), columns=train_features.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c247b623-1040-44e4-b44c-778ffb3a7a70",
    "_uuid": "811b92dab7c293cac4cc27c6de8b4ddb1d92c3f5"
   },
   "source": [
    "Exploratory analysis after scalling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "676261d9-c155-43b6-9a6c-2bdb34bbf629",
    "_uuid": "4f83c3ec2be9f33e765c794e3540e4990addeb7d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.201396</td>\n",
       "      <td>0.170101</td>\n",
       "      <td>0.184964</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.012888</td>\n",
       "      <td>0.013425</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.004894</td>\n",
       "      <td>0.013362</td>\n",
       "      <td>0.038237</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202185</td>\n",
       "      <td>0.206603</td>\n",
       "      <td>0.209336</td>\n",
       "      <td>0.195227</td>\n",
       "      <td>0.160288</td>\n",
       "      <td>0.089559</td>\n",
       "      <td>0.169752</td>\n",
       "      <td>0.089689</td>\n",
       "      <td>0.003350</td>\n",
       "      <td>0.004943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.262922</td>\n",
       "      <td>0.278488</td>\n",
       "      <td>0.386650</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.103060</td>\n",
       "      <td>0.106749</td>\n",
       "      <td>0.032016</td>\n",
       "      <td>0.063707</td>\n",
       "      <td>0.101124</td>\n",
       "      <td>0.168403</td>\n",
       "      <td>...</td>\n",
       "      <td>0.259307</td>\n",
       "      <td>0.263321</td>\n",
       "      <td>0.264107</td>\n",
       "      <td>0.250137</td>\n",
       "      <td>0.245510</td>\n",
       "      <td>0.200095</td>\n",
       "      <td>0.280592</td>\n",
       "      <td>0.224222</td>\n",
       "      <td>0.051108</td>\n",
       "      <td>0.060801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.150838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147727</td>\n",
       "      <td>0.147727</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.127907</td>\n",
       "      <td>0.065868</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>0.006024</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.240223</td>\n",
       "      <td>0.225610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.289773</td>\n",
       "      <td>0.289773</td>\n",
       "      <td>0.267442</td>\n",
       "      <td>0.197605</td>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.234940</td>\n",
       "      <td>0.033557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             aa_000        ab_000        ac_000        ad_000        ae_000  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.201396      0.170101      0.184964      0.000076      0.012888   \n",
       "std        0.262922      0.278488      0.386650      0.004138      0.103060   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.005587      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.150838      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.240223      0.225610      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             af_000        ag_000        ag_001        ag_002        ag_003  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.013425      0.001228      0.004894      0.013362      0.038237   \n",
       "std        0.106749      0.032016      0.063707      0.101124      0.168403   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...        ee_002        ee_003        ee_004        ee_005  \\\n",
       "count  ...  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean   ...      0.202185      0.206603      0.209336      0.195227   \n",
       "std    ...      0.259307      0.263321      0.264107      0.250137   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.005682      0.005814   \n",
       "50%    ...      0.147727      0.147727      0.136364      0.127907   \n",
       "75%    ...      0.272727      0.289773      0.289773      0.267442   \n",
       "max    ...      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             ee_006        ee_007        ee_008        ee_009        ef_000  \\\n",
       "count  60000.000000  60000.000000  60000.000000  60000.000000  60000.000000   \n",
       "mean       0.160288      0.089559      0.169752      0.089689      0.003350   \n",
       "std        0.245510      0.200095      0.280592      0.224222      0.051108   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.065868      0.019737      0.006024      0.000000      0.000000   \n",
       "75%        0.197605      0.078947      0.234940      0.033557      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "             eg_000  \n",
       "count  60000.000000  \n",
       "mean       0.004943  \n",
       "std        0.060801  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 170 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dbb2cb75-a047-4bcf-ac39-2ae33cfb25e5",
    "_uuid": "bb254c70492ae2dc067909ffe9eacd1d8b59c8b6"
   },
   "source": [
    "### Processing train labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "77438be6-c0d8-4f36-b0f1-10abad949034",
    "_uuid": "e54c0563d356ea380b6faea084a64b4bbcbedca6"
   },
   "source": [
    "Round values and replace -1 with 0 making all labels positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "963a166f-d692-4640-bd90-f77d78a4f606",
    "_uuid": "1129ee7e57fa74fa930f29bbf846c302cfc1b4ea"
   },
   "outputs": [],
   "source": [
    "train_labels = train_labels.apply(round)\n",
    "train_labels = train_labels.replace({-1:0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5099b0e3-dc6d-446b-94b4-ac7ee01a6aae",
    "_uuid": "b62194b0a9a44ff7221cf5b26aa75ac1a68a3e08"
   },
   "source": [
    "### Show labels porportion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "bd52b6c5-fe95-4ccf-8b64-75bb4a3f99b1",
    "_uuid": "56af87c846427516ab50a427668392938a5d709b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bar(train_labels.value_counts())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "c389f48d-44cc-4131-83a8-4bc463b701db",
    "_uuid": "a2f7cbc140ee84dc07d19ba21bb0a7a1451af5bc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if enable_correlation and enable_dendrogram:\n",
    "    corr_matrix = train_features.corr()\n",
    "    dendrogram(corr_matrix)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "6a4d29cd-72de-4cf8-ac02-671813606b08",
    "_uuid": "6aeb1c570b12610a9ab5d7f6591fc2bbdd5936f6"
   },
   "outputs": [],
   "source": [
    "if enable_correlation and enable_heatmap:\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax = sns.heatmap(corr_matrix, square=True, cmap='Purples', ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "8fce13a6-1a12-4bae-a535-f7104561d001",
    "_uuid": "be8f50fe068e8bd7cc21961382192555630c256e"
   },
   "outputs": [],
   "source": [
    "# to enable run correlation selection without univariate selection.\n",
    "best_train_features = train_features \n",
    "new_corr_matrix = best_train_features.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "7c38fcca-f3e5-47e7-a8fa-2e48f500af50",
    "_uuid": "de1c4bb1f9e48bc003f7ad74e9b0f8391ef4fa17"
   },
   "outputs": [],
   "source": [
    "if enable_univariate_selec:\n",
    "    if method_selec=='selectkbest':\n",
    "        selectKBest = SelectKBest(score_func=chi2, k=k_best)\n",
    "        selectKBest.fit(train_features, train_labels)\n",
    "        best_train_features = selectKBest.transform(train_features)\n",
    "\n",
    "        idxs_selected = selectKBest.get_support(indices=True)\n",
    "        best_train_features = train_features.iloc[:,idxs_selected]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "047ffebd-f220-4aad-b867-4c10f78c0cac",
    "_uuid": "0afcb511e696667d17ae0a5a20bb64a0b9cdc579"
   },
   "source": [
    "Selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_cell_guid": "1ed341d2-93a3-4296-9c95-8ebc3f0b5321",
    "_uuid": "dff67ba5d57484dfe01205f309ee7af52f5814c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['aa_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ah_000',\n",
      "       'ai_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000', 'aq_000',\n",
      "       'ar_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_007', 'ay_008',\n",
      "       'ay_009', 'az_000', 'az_001', 'az_002', 'az_005', 'ba_000', 'ba_001',\n",
      "       'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_008', 'ba_009',\n",
      "       'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000',\n",
      "       'bi_000', 'bj_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000',\n",
      "       'cc_000', 'ci_000', 'cj_000', 'ck_000', 'cl_000', 'cm_000', 'cn_000',\n",
      "       'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_007', 'cn_008', 'cn_009',\n",
      "       'cq_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cx_000',\n",
      "       'dd_000', 'df_000', 'dn_000', 'dq_000', 'eb_000', 'ec_00', 'ee_000',\n",
      "       'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if enable_univariate_selec:\n",
    "    if method_selec=='selectkbest':\n",
    "        print(best_train_features.columns) # selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "3a95a65c-5069-42be-ac93-ed0c6e844f76",
    "_uuid": "c7bfeed0e3fbd0b2e671d1cee0a4896ca5352131"
   },
   "outputs": [],
   "source": [
    "if enable_univariate_selec:\n",
    "    if method_selec=='selectkbest':\n",
    "        best_train_features.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b94de898-32e8-49a0-8d37-c781ab13bc95",
    "_uuid": "2f358f330a00cacb78207d5ed5ed6083dd02680e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if enable_univariate_selec:\n",
    "    if method_selec=='selectkbest':\n",
    "        new_corr_matrix = best_train_features.corr()\n",
    "        dendrogram(new_corr_matrix)\n",
    "        plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_cell_guid": "926721bb-fc9a-4b8c-84f4-ab1e4eebc54b",
    "_uuid": "1ceea95eff9c4163226e90d3421fac1fc2975c80"
   },
   "outputs": [],
   "source": [
    "if enable_correlation_selec:\n",
    "    new_new_corr_matrix = corr_drop(new_corr_matrix, factor)\n",
    "    print(f'Number of features selected is {len(new_new_corr_matrix.columns)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "639acda3-4937-43c9-beac-f24f6992d9db",
    "_uuid": "bc7ad0c5e13ecb90b2367eddcdf4e19723106189"
   },
   "outputs": [],
   "source": [
    "if enable_correlation_selec:\n",
    "    dendrogram(new_new_corr_matrix)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "4f09249f-16e0-403d-b52e-f87a62a342d2",
    "_uuid": "8479274abe37592f8363127d85068b1fac56facc"
   },
   "outputs": [],
   "source": [
    "if enable_correlation_selec:\n",
    "    fig, ax = plt.subplots(figsize=(10,10))\n",
    "    ax = sns.heatmap(new_new_corr_matrix, square=True, cmap='Purples', ax=ax)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_cell_guid": "748a8e72-958d-4999-91ca-4e3c5e640b5d",
    "_uuid": "cae14f3ae2dd210a5d98e5244fbc1888f5b85872"
   },
   "outputs": [],
   "source": [
    "if enable_correlation_selec:\n",
    "    best_train_features = best_train_features.loc[:,new_new_corr_matrix.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_cell_guid": "68cb66c6-13c3-4d38-a86f-6e59ee665e45",
    "_uuid": "483e6b2c196909b3df826eddbb5a54709cddf8ec"
   },
   "outputs": [],
   "source": [
    "if method_selec=='pca':\n",
    "    pca = PCA(pca_variance)\n",
    "    pca.fit(train_features)\n",
    "    best_train_features = pca.transform(train_features)\n",
    "    best_train_features = pd.DataFrame(best_train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "e90a56a5-d2ba-464f-ab8c-8a173e0c783c",
    "_uuid": "9715d933e649558ad526324dd56016700e49256c"
   },
   "outputs": [],
   "source": [
    "if method_selec=='pca':\n",
    "    print('Number of components {pca.n_components_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_cell_guid": "78a0e7c5-f8db-432c-bc5a-45663b456ba3",
    "_uuid": "5a43cee5c063be5936761cf8fcf19491328383dc"
   },
   "outputs": [],
   "source": [
    "# to enable run without balancing\n",
    "best_train_features_balanced = best_train_features\n",
    "train_labels_balanced = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_cell_guid": "90a7a94a-452a-4967-8a11-a11748d4472e",
    "_uuid": "a1bcdb546500d42d2779cef19f513e5c71022867"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportion balanced: 2/1\n"
     ]
    }
   ],
   "source": [
    "if enable_balancing:\n",
    "    idxs_pos = train_labels[train_labels==1].index\n",
    "    idxs_neg = train_labels[train_labels==0].sample(n=number_samples, replace=False, random_state=0).index\n",
    "    idxs_balanced = np.concatenate((idxs_pos,idxs_neg))\n",
    "    best_train_features_balanced = best_train_features.loc[idxs_balanced]\n",
    "    train_labels_balanced = train_labels.loc[idxs_balanced]\n",
    "    print(f'Proportion balanced: {int(number_samples/1000)}/1')\n",
    "\n",
    "best_test_features = test_features  \n",
    "if enable_normalization:\n",
    "    scaler.transform(best_test_features)\n",
    "    best_test_features = pd.DataFrame(scaler.transform(best_test_features), columns=best_test_features.columns)\n",
    "    \n",
    "if enable_univariate_selec:\n",
    "    if method_selec=='selectkbest':        \n",
    "        X = selectKBest.transform(best_test_features)\n",
    "        idxs_selected = selectKBest.get_support(indices=True)\n",
    "        best_test_features = best_test_features.iloc[:,idxs_selected]\n",
    "    if method_selec=='pca':        \n",
    "        best_test_features = pca.transform(best_test_features)\n",
    "if enable_correlation_selec:\n",
    "    best_test_features = best_test_features.loc[:,new_new_corr_matrix.columns]\n",
    "\n",
    "test_labels = test_labels.apply(round)\n",
    "test_labels = test_labels.replace({-1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                    Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_train_features_balanced, train_labels_balanced = pd.read_csv('x_train_cleaned.csv'),pd.read_csv('y_train_labels_cleaned.csv')\n",
    "best_test_features, test_labels = pd.read_csv('x_test_cleaned.csv'), pd.read_csv('y_test_labels_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                                                     Best So Far!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(max_depth=55, n_estimators=122, n_jobs=-1, oob_score=True,\n",
      "                      random_state=0)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     15625\n",
      "           1       0.40      0.98      0.57       375\n",
      "\n",
      "    accuracy                           0.97     16000\n",
      "   macro avg       0.70      0.97      0.78     16000\n",
      "weighted avg       0.99      0.97      0.97     16000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15079</td>\n",
       "      <td>546</td>\n",
       "      <td>7</td>\n",
       "      <td>368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      tn   fp  fn   tp\n",
       "0  15079  546   7  368"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    8960\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "rfc = RandomForestRegressor(n_estimators=122, max_depth=55, oob_score = True, random_state=0, n_jobs=-1)\n",
    "rfc.fit(best_train_features_balanced, train_labels_balanced)\n",
    "print(rfc)\n",
    "\n",
    "\n",
    "y_pred = rfc.predict(best_test_features)\n",
    "y_pred = np.round(y_pred)\n",
    "report = classification_report(test_labels, y_pred)\n",
    "print(report)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(test_labels, y_pred).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "display(cm)\n",
    "\n",
    "total_cost = 10*cm.fp + 500*cm.fn\n",
    "print(total_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tn   fp  fn   tp\n",
      "0  15159  466  10  365\n",
      "0    9660\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "hgbc = HistGradientBoostingClassifier(learning_rate=0.4,max_depth=20,min_samples_leaf=20,max_bins=30, random_state=42)\n",
    "rbc = RandomForestClassifier(n_jobs=-1)\n",
    "# rfc = RandomForestRegressor(n_estimators=122, max_depth=55, oob_score = True, random_state=0, n_jobs=-1)\n",
    "\n",
    "voting_regressor = VotingClassifier(estimators=[\n",
    "     ('rbc', rbc), ('hbc', hgbc)], voting='soft')\n",
    "\n",
    "# Fit the VotingRegressor\n",
    "voting_regressor.fit(best_train_features_balanced, train_labels_balanced)\n",
    "\n",
    "\n",
    "y_pred = voting_regressor.predict(best_test_features)\n",
    "y_pred = np.round(y_pred)\n",
    "report = classification_report(test_labels, y_pred)\n",
    "\n",
    "\n",
    "cm = confusion_matrix(test_labels, y_pred).ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "print(cm)\n",
    "\n",
    "total_cost = 10*cm.fp + 500*cm.fn\n",
    "print(total_cost)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.datasets import make_classification\n",
    "# from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300],\n",
    "#     'max_depth': [5, 10, 15, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4]\n",
    "# }\n",
    "\n",
    "# # Create the RandomForestClassifier\n",
    "# rf_clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# # Perform the grid search with cross-validation\n",
    "# grid_search = GridSearchCV(rf_clf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "# grid_search.fit(best_train_features_balanced, train_labels_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    13820\n",
      "dtype: int64\n",
      "0    15290\n",
      "dtype: int64\n",
      "0    10930\n",
      "dtype: int64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m clf8 \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m clf \u001b[38;5;129;01min\u001b[39;00m [clf1, clf2,clf4, clf5, clf6, clf7,clf8]:\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_train_features_balanced\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels_balanced\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict(best_test_features)\n\u001b[1;32m     18\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mround(y_pred)\n",
      "File \u001b[0;32m~/anaconda3/envs/zen/lib/python3.9/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/zen/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:784\u001b[0m, in \u001b[0;36mBaseGradientBoosting.fit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_resize_state()\n\u001b[1;32m    783\u001b[0m \u001b[38;5;66;03m# fit the boosting stages\u001b[39;00m\n\u001b[0;32m--> 784\u001b[0m n_stages \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stages\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbegin_at_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmonitor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# change shape of arrays after fit (early-stopping or additional ests)\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_stages \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/zen/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:880\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stages\u001b[0;34m(self, X, y, raw_predictions, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor)\u001b[0m\n\u001b[1;32m    873\u001b[0m         initial_loss \u001b[38;5;241m=\u001b[39m factor \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss(\n\u001b[1;32m    874\u001b[0m             y_true\u001b[38;5;241m=\u001b[39my_oob_masked,\n\u001b[1;32m    875\u001b[0m             raw_prediction\u001b[38;5;241m=\u001b[39mraw_predictions[\u001b[38;5;241m~\u001b[39msample_mask],\n\u001b[1;32m    876\u001b[0m             sample_weight\u001b[38;5;241m=\u001b[39msample_weight_oob_masked,\n\u001b[1;32m    877\u001b[0m         )\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# fit next stage of trees\u001b[39;00m\n\u001b[0;32m--> 880\u001b[0m raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_stage\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_predictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_csr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_csr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;66;03m# track loss\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m do_oob:\n",
      "File \u001b[0;32m~/anaconda3/envs/zen/lib/python3.9/site-packages/sklearn/ensemble/_gb.py:490\u001b[0m, in \u001b[0;36mBaseGradientBoosting._fit_stage\u001b[0;34m(self, i, X, y, raw_predictions, sample_weight, sample_mask, random_state, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    487\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;241m*\u001b[39m sample_mask\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat64)\n\u001b[1;32m    489\u001b[0m X \u001b[38;5;241m=\u001b[39m X_csc \u001b[38;5;28;01mif\u001b[39;00m X_csc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n\u001b[0;32m--> 490\u001b[0m \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_g_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    492\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;66;03m# update tree leaves\u001b[39;00m\n\u001b[1;32m    495\u001b[0m X_for_tree_update \u001b[38;5;241m=\u001b[39m X_csr \u001b[38;5;28;01mif\u001b[39;00m X_csr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\n",
      "File \u001b[0;32m~/anaconda3/envs/zen/lib/python3.9/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/zen/lib/python3.9/site-packages/sklearn/tree/_classes.py:1377\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m   1349\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m \n\u001b[1;32m   1351\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1377\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/zen/lib/python3.9/site-packages/sklearn/tree/_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[0;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    463\u001b[0m         splitter,\n\u001b[1;32m    464\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    470\u001b[0m     )\n\u001b[0;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, StackingClassifier, VotingClassifier, ExtraTreesClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Training classifiers\n",
    "clf1 = AdaBoostClassifier(random_state=0)\n",
    "clf2 = BaggingClassifier(random_state=0, n_jobs=-1)\n",
    "clf4 = ExtraTreesClassifier(random_state=0, n_jobs=-1)\n",
    "clf5 = GradientBoostingClassifier()\n",
    "clf6 = LogisticRegression(n_jobs=-1)\n",
    "clf7 = HistGradientBoostingClassifier()\n",
    "clf8 = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "for clf in [clf1, clf2,clf4, clf5, clf6, clf7,clf8]:\n",
    "   \n",
    "    clf.fit(best_train_features_balanced, train_labels_balanced)\n",
    "\n",
    "    y_pred = clf.predict(best_test_features)\n",
    "    y_pred = np.round(y_pred)\n",
    "    report = classification_report(test_labels, y_pred)\n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(test_labels, y_pred).ravel()\n",
    "    cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "    # print(cm)\n",
    "    \n",
    "    total_cost = 10*cm.fp + 500*cm.fn\n",
    "    print(total_cost)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_label = best_train_features_balanced.values, train_labels_balanced.values\n",
    "x_test, y_test = best_test_features.values, test_labels.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import ipdb \n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        x = torch.tensor(self.data[index])\n",
    "        y = torch.tensor(self.labels[index])\n",
    "        return x, y\n",
    "\n",
    "\n",
    "train_dataset = CustomDataset(x_train, x_label)\n",
    "test_dataset = CustomDataset(x_test, y_test)\n",
    "\n",
    "dataset =[train_dataset, test_dataset]\n",
    "\n",
    "dataloader = {}\n",
    "for idx,split in enumerate(['train', 'test']):\n",
    "  dataloader[split] = DataLoader(\n",
    "    dataset[idx],\n",
    "    batch_size=64,\n",
    "    shuffle=(split == 'train'),\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "      \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict, OrderedDict\n",
    "from sconce import sconce\n",
    "\n",
    "from sconce import sconce\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import *\n",
    "from torch.optim.lr_scheduler import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import *\n",
    "from torchvision.transforms import *\n",
    "import torch.optim as optim\n",
    "\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.linear1 = nn.Linear(84, 32)\n",
    "        self.linear2 = nn.Linear(32, 16)\n",
    "        self.linear3 = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x.float()))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        x = torch.sigmoid(self.linear3(x))\n",
    "        return x\n",
    "        \n",
    "model = BinaryClassifier().to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def focal_loss(input, target, gamma=2.0, alpha=0.25, reduction='mean'):\n",
    "  \n",
    "    bcs = nn.BCELoss()\n",
    "    bce_loss = bcs(input, target)\n",
    "    \n",
    "    # Compute the modulating factor\n",
    "    pt = torch.exp(-bce_loss)\n",
    "    modulating_factor = (1 - pt) ** gamma\n",
    "    \n",
    "    # Compute the final loss\n",
    "    focal_loss = alpha * modulating_factor * bce_loss\n",
    "    \n",
    "    if reduction == 'mean':\n",
    "        return focal_loss.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return focal_loss.sum()\n",
    "    else:\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.BCELoss()\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=10, eta_min=1e-7)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in tqdm(dataloader['train'], desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = focal_loss(outputs, labels.unsqueeze(1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {running_loss/len(dataloader['train']):.4f}\")\n",
    "\n",
    "    # Testing loop\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader['test']:\n",
    "            inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "            outputs = model(inputs)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "        print(f\"Test Accuracy: {100 * correct / total:.2f}%\")\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(torch.tensor(x_test).to('cuda'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.argmax(y_pred,dim=1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.astype(np.int64)\n",
    "\n",
    "cm = confusion_matrix(test_labels, y_pred)#.ravel()\n",
    "cm = pd.DataFrame(cm.reshape((1,4)), columns=['tn', 'fp', 'fn', 'tp'])\n",
    "print(cm)\n",
    "\n",
    "total_cost = 10*cm.fp + 500*cm.fn\n",
    "print(total_cost)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 13327,
     "sourceId": 18366,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 283,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
